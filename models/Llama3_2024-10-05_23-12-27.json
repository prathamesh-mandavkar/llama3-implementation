{"dim": 128, "n_layers": 8, "n_heads": 4, "n_kv_heads": 1, "vocab_size": 512, "multiple_of": 256, "ffn_dim_multiplier": null, "norm_eps": 1e-05, "rope_theta": 10000, "max_batch_size": 32, "max_seq_len": 512, "device": "cpu", "dropout_rate": 0.1}